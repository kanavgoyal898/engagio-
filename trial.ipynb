{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **engagio:** Engagement Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **File Handling Cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import pandas\n",
    "\n",
    "PATH = 'DAiSEE/DataSet/'\n",
    "\n",
    "FPS = 30\n",
    "BATCH_SIZE = 16\n",
    "VIDEO_LENGTH = 10\n",
    "FRAME_INTERVAL = 2\n",
    "\n",
    "def get_subdirectories(path, sort=False):\n",
    "    \"\"\"Get a list of sub-directories in parent directory 'path'.\"\"\"\n",
    "    sub_directories = [os.path.join(path, subdir) for subdir in os.listdir(path) if os.path.isdir(os.path.join(path, subdir))]\n",
    "    \n",
    "    if sort:\n",
    "        sub_directories.sort()\n",
    "    else:\n",
    "        random.shuffle(sub_directories)\n",
    "    \n",
    "    return sub_directories\n",
    "\n",
    "def get_videos(path, sort=False):\n",
    "    \"\"\"Get a list of video paths from a directory 'path'.\"\"\"\n",
    "    videos = [os.path.join(path, file) for file in os.listdir(path) if file.endswith(('.mp4', '.avi', '.mov'))]\n",
    "    \n",
    "    if sort:\n",
    "        videos.sort()\n",
    "    else:\n",
    "        random.shuffle(videos)\n",
    "    \n",
    "    return videos\n",
    "\n",
    "def get_video_paths(path, sort=False):\n",
    "    \"\"\"Get all video paths in a dataset.\"\"\"\n",
    "    videos = []\n",
    "    subject_list = get_subdirectories(path)\n",
    "    \n",
    "    for subject in subject_list:\n",
    "        subject_subdir_list = get_subdirectories(subject, sort)\n",
    "        \n",
    "        for subdir in subject_subdir_list:\n",
    "            subdir_video_paths = get_videos(subdir, sort)\n",
    "            videos.extend(subdir_video_paths)\n",
    "    \n",
    "    return videos\n",
    "\n",
    "def get_frames(subject_videos, frame_interval=FRAME_INTERVAL, resize_to=None):\n",
    "    \"\"\"Get frames from a list of 'subject_videos' paths.\"\"\"\n",
    "    frames_subject = []\n",
    "\n",
    "    for subject_video in subject_videos:\n",
    "        video_capture = cv2.VideoCapture(subject_video)\n",
    "        \n",
    "        if not video_capture.isOpened():\n",
    "            print(f\"Error opening video file {subject_video}\")\n",
    "            continue\n",
    "\n",
    "        count = 0\n",
    "        frames = []\n",
    "\n",
    "        while True:\n",
    "            success, frame = video_capture.read()\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            count += 1\n",
    "            if count % frame_interval == 0:\n",
    "                if resize_to:\n",
    "                    frame = cv2.resize(frame, resize_to)\n",
    "\n",
    "                # Convert the first frame from BGR to RGB\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frames.append(frame)\n",
    "\n",
    "        video_capture.release()\n",
    "\n",
    "        if frames:\n",
    "            frames_required = (FPS * VIDEO_LENGTH) // frame_interval\n",
    "            frames = frames[:frames_required]\n",
    "            while len(frames) < frames_required:\n",
    "                frames.append(frames[-1])\n",
    "            frames_subject.append(frames)\n",
    "        else:\n",
    "            print(f\"No frames extracted from video file {subject_video}\")\n",
    "\n",
    "    return frames_subject if frames_subject else [[]]\n",
    "\n",
    "def get_labels(paths):\n",
    "    \"\"\"Get labels for boredom, engagement, confusion, frustration.\"\"\"\n",
    "    data = pandas.read_csv(f'DAiSEE/Labels/AllLabels.csv')\n",
    "    tails = [os.path.split(path)[1] for path in paths]\n",
    "    filtered_data = data[data['ClipID'].isin(tails)]\n",
    "    engagement_data = filtered_data[['Engagement']]\n",
    "    return engagement_data.values\n",
    "\n",
    "def load_data(path, dataset, batch_size=None):\n",
    "    \"\"\"Load random videos from 'path'.\"\"\"\n",
    "    path = os.path.join(path, dataset)\n",
    "    paths = get_video_paths(path, sort=True)\n",
    "    if batch_size is not None:\n",
    "        paths = random.sample(paths, batch_size)\n",
    "    X = get_frames(paths, FRAME_INTERVAL)\n",
    "    Y = get_labels(paths)\n",
    "\n",
    "    return paths, X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visual Features Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste in your code here @AlakhsimarSingh\n",
    "\n",
    "# fan_in_A = number of input features\n",
    "fan_in_A = 0    # replace 0 with the actual value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Physiological Features Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paste in your code here @NischayVerma\n",
    "\n",
    "# fan_in_N = number of input features\n",
    "fan_in_N = 0    # replace 0 with the actual value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Device Auto Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imbalance import *\n",
    "from architecture import *\n",
    "\n",
    "class EngagementModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, fan_in_A, fan_in_N, fan_out_A, fan_out_N, fan_out, n_embd, head_size, n_heads, n_blocks, ffwd_mul):\n",
    "        super().__init__()\n",
    "        self.fan_out = fan_out\n",
    "        self.signal_encoder_A = SignalEncoder(fan_in_A, fan_out_A, n_embd, head_size, n_heads, n_blocks, ffwd_mul)\n",
    "        self.signal_encoder_N = SignalEncoder(fan_in_N, fan_out_N, n_embd, head_size, n_heads, n_blocks, ffwd_mul)\n",
    "        self.lm_head = torch.nn.Sequential(\n",
    "                            torch.nn.Linear(fan_out_A + fan_out_N, fan_out),\n",
    "                            torch.nn.GELU()\n",
    "                        )\n",
    "\n",
    "    def forward(self, x_A, x_N, idx=None, weighted=False):\n",
    "        x_A = self.signal_encoder_A(x_A)\n",
    "        x_N = self.signal_encoder_N(x_N)\n",
    "        \n",
    "        out = torch.cat([x_A, x_N], -1)\n",
    "        out = self.lm_head(out)\n",
    "        B, T, C = out.shape\n",
    "\n",
    "        loss = None\n",
    "        if idx is not None:\n",
    "            x = out.float()\n",
    "            y = idx.unsqueeze(1).repeat(1, T, 1).float()\n",
    "            x = x.view(-1, self.fan_out)\n",
    "            y = y.view(-1).long()\n",
    "            criterion = SelfAdjDiceLoss() if weighted else torch.nn.CrossEntropyLoss()\n",
    "            loss = criterion(x, y)\n",
    "            # loss = torch.nn.functional.cross_entropy(x, y, weight=torch.tensor([1/61, 1/455, 1/4422, 1/3987], dtype=x.dtype, device=x.device) if weighted else None)\n",
    "        \n",
    "        return out, loss\n",
    "\n",
    "# NOTE: n_embd = head_size * n_heads\n",
    "model = EngagementModel(fan_in_A, fan_in_N, 4, 4, 4, 64, 16, 4, 8, 4)\n",
    "model.to(device)\n",
    "\n",
    "sum(p.nelement() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(logits, true_labels):\n",
    "    logits = logits.to(device)\n",
    "    true_labels = true_labels.to(device)\n",
    "\n",
    "    B, T, C = logits.shape\n",
    "    logits = logits.view(-1, C)\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=-1)  \n",
    "    \n",
    "    predicted_classes = torch.argmax(probabilities, dim=-1)\n",
    "\n",
    "    predicted_classes = predicted_classes.view(B, T, 1)\n",
    "    true_labels = true_labels.unsqueeze(1).repeat(1, T, 1)\n",
    "    \n",
    "    correct_predictions = (predicted_classes == true_labels).float().sum()\n",
    "    total_predictions = B*T\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acci = []\n",
    "lossi = []\n",
    "\n",
    "lr_i = 1e-3\n",
    "lr_f = 1e-6\n",
    "iters = 100\n",
    "\n",
    "for i in range(iters):\n",
    "    lr = 1e-3 + ((lr_f - lr_i)/iters)*i\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    X_batch, Y_batch = load_data(PATH, 'Train', BATCH_SIZE)\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # code for X_batch_A, X_batch_N\n",
    "    X_batch_A = X_batch                 # replace X_batch_A with the actual code @AlakhsimarSingh\n",
    "    X_batch_N = X_batch                 # replace X_batch_N with the actual code @NischayVerma\n",
    "    X_batch_A.requires_grad = True    \n",
    "    X_batch_N.requires_grad = True    \n",
    "    \n",
    "    logits, loss = model(X_batch_A.to(device), X_batch_N.to(device), Y_batch.to(device), weighted=True)\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    acc = compute_accuracy(logits, Y_batch)\n",
    "    print(f'{i} iteration, loss: {loss:.4f}, acc: {acc:.4f}')\n",
    "\n",
    "    acci.append(acc)\n",
    "    lossi.append(loss.item())\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'Average loss: {sum(lossi)/len(lossi):.4f}, Average accuracy: {sum(acci)/len(acci):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax1.plot(lossi, color='blue')\n",
    "ax1.set_title('Loss Plot')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Lossi Values')\n",
    "\n",
    "ax2.plot(acci, color='green')\n",
    "ax2.set_title('Acci Plot')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy Values')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Metrics on Validation Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acci = []\n",
    "lossi = []\n",
    "for i in range(10):\n",
    "    X_batch, Y_batch = load_data(PATH, 'Validation', BATCH_SIZE)\n",
    "    \n",
    "    # ----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # code for X_batch_A, X_batch_N\n",
    "    X_batch_A = X_batch                 # replace X_batch_A with the actual code @AlakhsimarSingh\n",
    "    X_batch_N = X_batch                 # replace X_batch_N with the actual code @NischayVerma\n",
    "    X_batch_A.requires_grad = True    \n",
    "    X_batch_N.requires_grad = True    \n",
    "    \n",
    "    logits, loss = model(X_batch_A.to(device), X_batch_N.to(device), Y_batch.to(device), weighted=True)\n",
    "\n",
    "    # ----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    logits, loss = model(X_batch.to(device), X_batch.to(device), Y_batch.to(device))\n",
    "\n",
    "    acc = compute_accuracy(logits, Y_batch)\n",
    "\n",
    "    acci.append(acc)\n",
    "    lossi.append(loss.item())\n",
    "\n",
    "print(f'Average loss: {sum(lossi)/len(lossi):.4f}, Average accuracy: {sum(acci)/len(acci):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Late Fusion Techniques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @AlakhsimarSingh ML code starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @NischayVerma ML code starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LateFusion(torch.nn.Module):\n",
    "    def __init__(self, num_modalities, num_classses, n_embd):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classses\n",
    "        self.num_modalities = num_modalities\n",
    "        self.wei = torch.nn.Sequential(\n",
    "            torch.nn.Linear(self.num_modalities, 1),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, logits, y=None):\n",
    "        out = self.wei(logits)\n",
    "        out = out.squeeze(-1)\n",
    "        loss = None\n",
    "        if y is not None:\n",
    "            x = out.float()\n",
    "            y = y.long()\n",
    "            loss = torch.nn.functional.cross_entropy(x, y)\n",
    "        return out, loss\n",
    "    \n",
    "model = LateFusion(2, 4, 64)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_accuracy(logits, true_labels):\n",
    "    logits = logits.to(device)\n",
    "    true_labels = true_labels.to(device)\n",
    "    \n",
    "    B, C = logits.shape\n",
    "    logits = logits.view(-1, C)\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    \n",
    "    predicted_classes = torch.argmax(probabilities, dim=-1)\n",
    "    \n",
    "    correct_predictions = (predicted_classes == true_labels).float().sum()\n",
    "    total_predictions = B\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    \n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acci = []\n",
    "lossi = []\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for i in range(1000):\n",
    "    X_batch, Y_batch = load_data(PATH, 'Train', BATCH_SIZE)\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # add your signals here\n",
    "    X_batch_A = X_batch     # @AlakhsimarSingh signals\n",
    "    X_batch_N = X_batch     # @NischayVerma signals\n",
    "    # ------------------------------------------\n",
    "\n",
    "    X_batch = torch.stack([X_batch_A, X_batch_N], dim=-1)\n",
    "    logits, loss = model(X_batch.to(device), Y_batch.to(device))\n",
    "\n",
    "    acc = _compute_accuracy(logits, Y_batch)\n",
    "    print(f'{i} iteration, loss: {loss.item():.4f}, acc: {acc:.4f}')\n",
    "\n",
    "    lossi.append(loss.item())\n",
    "    acci.append(acc)\n",
    "\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'Average loss: {sum(lossi)/len(lossi):.4f}, Average accuracy: {sum(acci)/len(acci):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ax1.plot(lossi, color='blue')\n",
    "ax1.set_title('Loss Plot')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Lossi Values')\n",
    "\n",
    "ax2.plot(acci, color='green')\n",
    "ax2.set_title('Acci Plot')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy Values')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acci = []\n",
    "lossi = []\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for i in range(1000):\n",
    "    X_batch, Y_batch = load_data(PATH, 'Validation', BATCH_SIZE)\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # add your signals here\n",
    "    X_batch_A = X_batch     # @AlakhsimarSingh signals\n",
    "    X_batch_N = X_batch     # @NischayVerma signals\n",
    "    # ------------------------------------------\n",
    "\n",
    "    X_batch = torch.stack([X_batch_A, X_batch_N], dim=-1)\n",
    "    logits, loss = model(X_batch.to(device), Y_batch.to(device))\n",
    "\n",
    "    acc = _compute_accuracy(logits, Y_batch)\n",
    "\n",
    "    lossi.append(loss.item())\n",
    "    acci.append(acc)\n",
    "\n",
    "print(f'Average loss: {sum(lossi)/len(lossi):.4f}, Average accuracy: {sum(acci)/len(acci):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
